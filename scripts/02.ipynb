{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312fa115-6656-4648-a4e7-ec7d33a7712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_VERSION'] = '3.5.0'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "import pydeequ\n",
    "from pydeequ.analyzers import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('regression') \\\n",
    "    .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension') \\\n",
    "    .config('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog') \\\n",
    "    .config('spark.jars.packages', pydeequ.deequ_maven_coord) \\\n",
    "    .config('spark.jars.excludes', pydeequ.f2j_maven_coord) \\\n",
    "    .config('spark.sql.warehouse.dir', '../spark-warehouse') \\\n",
    "    .config('spark.driver.extraJavaOptions', '-Dderby.system.home=\"../metastore_db/\"') \\\n",
    "    .config('spark.driver.memory', '10g') \\\n",
    "    .config('spark.driver.maxResultSize', '10g') \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db18326b-350b-47eb-b3a2-6b21c50d2583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-----------+\n",
      "|namespace|tableName       |isTemporary|\n",
      "+---------+----------------+-----------+\n",
      "|otherdb  |crime           |false      |\n",
      "|otherdb  |dg_orders       |false      |\n",
      "|otherdb  |trip            |false      |\n",
      "|otherdb  |vw_crime        |false      |\n",
      "|otherdb  |vw_trip_duration|false      |\n",
      "|otherdb  |vw_trip_report  |false      |\n",
      "+---------+----------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SHOW TABLES FROM OtherDB').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500abe61-180e-435d-ae0b-0ded3c1d5233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+----+---------+-------+\n",
      "|amount|duration|distance|hour|passenger|payment|\n",
      "+------+--------+--------+----+---------+-------+\n",
      "|35.35 |1200    |5.57    |0   |NULL     |0      |\n",
      "|20.47 |479     |2.6     |0   |NULL     |0      |\n",
      "|23.83 |737     |3.7     |0   |NULL     |0      |\n",
      "+------+--------+--------+----+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM OtherDB.vw_trip_duration LIMIT 3').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cac32ff-42ee-4efa-b900-9d2f625e0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sql('''\n",
    "    SELECT * \n",
    "    FROM OtherDB.vw_trip_duration\n",
    "    WHERE passenger IS NOT NULL\n",
    "    LIMIT 1000000\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67810ae2-d2bd-42e3-9b7e-d0c1deb50305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------------------+\n",
      "|Column1 |Column2  |Correlation           |\n",
      "+--------+---------+----------------------+\n",
      "|amount  |amount   |1.0                   |\n",
      "|amount  |duration |0.23189308969417818   |\n",
      "|amount  |distance |0.1384123937284394    |\n",
      "|amount  |hour     |0.02078728915571583   |\n",
      "|amount  |passenger|0.02987173727206933   |\n",
      "|amount  |payment  |NaN                   |\n",
      "|duration|amount   |0.23189308969417818   |\n",
      "|duration|duration |1.0                   |\n",
      "|duration|distance |0.0345320360099649    |\n",
      "|duration|hour     |-0.0021780198183030354|\n",
      "|duration|passenger|0.019065320741348347  |\n",
      "|duration|payment  |NaN                   |\n",
      "|distance|amount   |0.1384123937284394    |\n",
      "|distance|duration |0.03453203600996489   |\n",
      "|distance|distance |1.0                   |\n",
      "|distance|hour     |0.0015839586060821895 |\n",
      "|distance|passenger|0.003116172311718919  |\n",
      "|distance|payment  |NaN                   |\n",
      "|hour    |amount   |0.020787289155715837  |\n",
      "|hour    |duration |-0.002178019818303036 |\n",
      "+--------+---------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_pairs = [(col1, col2) for col1 in data.columns for col2 in data.columns]\n",
    "\n",
    "correlation_df = spark.createDataFrame(\n",
    "    [(col1, col2, data.select(col1, col2).corr(col1, col2)) for col1, col2 in column_pairs],\n",
    "    ['Column1', 'Column2', 'Correlation']\n",
    ")\n",
    "\n",
    "correlation_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c840d9-d8d0-4ec4-b158-aba4840ce4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 21.4873\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "assembler = VectorAssembler(inputCols=['duration', 'hour', 'distance'], outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "\n",
    "train_data, test_data = data.randomSplit([0.8, 0.2])\n",
    "lr = LinearRegression(featuresCol='features', labelCol='amount')\n",
    "lrModel = lr.fit(train_data)\n",
    "\n",
    "predictions = lrModel.transform(test_data)\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='amount', predictionCol='prediction', metricName='rmse')\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "771fe5bb-4fdd-41c6-b99c-c43be975a13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([0.002, 0.0824, 0.089])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrModel.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7f5ec2-fee8-43c9-a975-598a0509b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sqrt, abs, when\n",
    "\n",
    "predictions_with_distance = predictions.withColumn(\n",
    "    'distance', sqrt(abs(col('prediction') - col('amount')))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0531755-d1c5-4775-9ae2-ce018e40c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_color(distance):\n",
    "    return 'red' if distance > 3 else 'green'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f2357b-2e6f-4714-b15e-6f57908dc46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col, sqrt, abs, when, StringType\n",
    "\n",
    "distance_to_color_udf = udf(distance_to_color, StringType())\n",
    "\n",
    "predictions_colored = predictions_with_distance.withColumn(\n",
    "    'color', distance_to_color_udf(col('distance'))\n",
    ")\n",
    "\n",
    "pdf = predictions_colored.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66034ef8-657d-484c-ae1e-75b4f5a61dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(\n",
    "    pdf,\n",
    "    x='amount',\n",
    "    y='prediction',\n",
    "    color='color',\n",
    "    trendline='ols'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    xaxis_showgrid=False,\n",
    "    yaxis_showgrid=False,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0ffb1b-387c-4e1c-8957-269c237305b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel.write().overwrite().save('trip_regression_model')\n",
    "#loaded_model = PipelineModel.load('trip_regression_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38354084-d8c3-4bc3-8629-928f888f44bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
