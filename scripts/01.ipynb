{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02dd7b09-39dd-4f2d-84e2-9005c0482904",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ../lake/*\n",
    "! rm -r ../spark-warehouse/*\n",
    "! rm -r ../metastore_db/*\n",
    "! rm -r ../temp/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf8aa7a-5d14-462e-9b05-ef27feef4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_VERSION'] = '3.5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e22f5605-5431-450c-b004-00ca6001b0d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T09:16:28.238022Z",
     "start_time": "2024-10-14T09:16:28.221689Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "import pydeequ\n",
    "from pydeequ.analyzers import *\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').appName('quick-start') \\\n",
    "    .config('spark.sql.extensions', 'io.delta.sql.DeltaSparkSessionExtension') \\\n",
    "    .config('spark.sql.catalog.spark_catalog', 'org.apache.spark.sql.delta.catalog.DeltaCatalog') \\\n",
    "    .config('spark.jars.packages', pydeequ.deequ_maven_coord) \\\n",
    "    .config('spark.jars.excludes', pydeequ.f2j_maven_coord) \\\n",
    "    .config('spark.sql.warehouse.dir', '../spark-warehouse') \\\n",
    "    .config('spark.driver.extraJavaOptions', '-Dderby.system.home=\"../metastore_db/\"') \\\n",
    "    .config('spark.driver.memory', '10g') \\\n",
    "    .config('spark.driver.maxResultSize', '10g') \\\n",
    "    .config('spark.sql.repl.eagerEval.enabled', True) \\\n",
    "    .config('spark.databricks.delta.schema.autoMerge.enabled', True) \\\n",
    "    .config('spark.databricks.delta.autoCompact.enabled', True) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d44acf-d819-4963-8dc8-896d4fe9778e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|database_name|\n",
      "+-------------+\n",
      "|default      |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT namespace as database_name FROM {df}',df = spark.sql('SHOW DATABASES')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "394ff16a-5da8-436d-b627-434b1e0ff1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|database_name |\n",
      "+--------------+\n",
      "|adventureworks|\n",
      "|default       |\n",
      "|otherdb       |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('CREATE DATABASE IF NOT EXISTS AdventureWorks')\n",
    "spark.sql('CREATE DATABASE IF NOT EXISTS OtherDB')\n",
    "\n",
    "spark.sql('SELECT namespace as database_name FROM {df}',df = spark.sql('SHOW DATABASES')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31566e7-07c4-4ed8-b37b-cc5d60ee5752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|current_database|\n",
      "+----------------+\n",
      "|adventureworks  |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('USE AdventureWorks')\n",
    "spark.sql('SELECT CURRENT_SCHEMA() AS current_database').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20771810-413d-479c-911c-3f3c015cd46a",
   "metadata": {},
   "source": [
    "## Load data into Bronze zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab0a468f-5203-4790-8e96-49b705539074",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbc_options = {\n",
    "      'url': 'jdbc:sqlserver://localhost:1433;database=AdventureWorks2022;trustServerCertificate=true',\n",
    "      'driver': 'com.microsoft.sqlserver.jdbc.SQLServerDriver',\n",
    "      'user': 'SA',\n",
    "      'password': 'PiIs&&&31415926535'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2dce30-a5c3-4a36-ad80-875f2ab3a531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+\n",
      "|column_name          |data_type|\n",
      "+---------------------+---------+\n",
      "|BusinessEntityID     |int      |\n",
      "|PersonType           |string   |\n",
      "|NameStyle            |boolean  |\n",
      "|Title                |string   |\n",
      "|FirstName            |string   |\n",
      "|MiddleName           |string   |\n",
      "|LastName             |string   |\n",
      "|Suffix               |string   |\n",
      "|EmailPromotion       |int      |\n",
      "|AdditionalContactInfo|string   |\n",
      "|Demographics         |string   |\n",
      "|rowguid              |string   |\n",
      "|ModifiedDate         |timestamp|\n",
      "+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Person.Person) t'\n",
    "person_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(person_df.dtypes, ['column_name', 'data_type']).show(person_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8bfb56f-2e8d-4bd4-922e-c25c061ee539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n",
      "|database_name |table_name|\n",
      "+--------------+----------+\n",
      "|adventureworks|person    |\n",
      "+--------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.Person (\n",
    "    BusinessEntityID INT,\n",
    "    PersonType STRING,\n",
    "    Title STRING,\n",
    "    FirstName STRING,\n",
    "    MiddleName STRING,\n",
    "    LastName STRING,\n",
    "    Suffix STRING\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Person/Person'\n",
    "'''\n",
    "spark.sql(sql)\n",
    "\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0aaa4b22-f425-4b7f-b314-bc3d0dd9c792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|person_row_count|\n",
      "+----------------+\n",
      "|19972           |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.Person\n",
    "    SELECT BusinessEntityID, PersonType, Title, FirstName, MiddleName, LastName, Suffix FROM {df}\n",
    "    ''', df = person_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS person_row_count FROM AdventureWorks.Person').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5911c774-6cea-49e9-9a54-d2aafb70cad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|column_name     |data_type|\n",
      "+----------------+---------+\n",
      "|BusinessEntityID|int      |\n",
      "|rowguid         |string   |\n",
      "|ModifiedDate    |timestamp|\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Person.BusinessEntity) t'\n",
    "entity_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(entity_df.dtypes, ['column_name', 'data_type']).show(entity_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a8f2d78-fb39-425a-909e-aa1fb9322add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|database_name |table_name    |\n",
      "+--------------+--------------+\n",
      "|adventureworks|businessentity|\n",
      "|adventureworks|person        |\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.BusinessEntity (\n",
    "    BusinessEntityID INT,\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Person/BusinessEntity'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae27e97-7a0c-4145-9e22-367565276e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|entity_row_count|\n",
      "+----------------+\n",
      "|20777           |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.BusinessEntity\n",
    "    SELECT BusinessEntityID, ModifiedDate\n",
    "    FROM {df}\n",
    "''', df = entity_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS entity_row_count FROM AdventureWorks.BusinessEntity').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e2f6ff-8b97-4743-aa80-2ac4297662d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|column_name     |data_type|\n",
      "+----------------+---------+\n",
      "|BusinessEntityID|int      |\n",
      "|EmailAddressID  |int      |\n",
      "|EmailAddress    |string   |\n",
      "|rowguid         |string   |\n",
      "|ModifiedDate    |timestamp|\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Person.EmailAddress) t'\n",
    "email_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(email_df.dtypes, ['column_name', 'data_type']).show(email_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "236f363e-721f-4c06-94a2-e1317120f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|database_name |table_name    |\n",
      "+--------------+--------------+\n",
      "|adventureworks|businessentity|\n",
      "|adventureworks|emailaddress  |\n",
      "|adventureworks|person        |\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.EmailAddress (\n",
    "    BusinessEntityID INT,\n",
    "    EmailAddress STRING,\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Person/EmailAddress'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcacaf4d-381c-4dd4-af0f-61ece52aaf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|email_row_count|\n",
      "+---------------+\n",
      "|19972          |\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.EmailAddress\n",
    "    SELECT BusinessEntityID, EmailAddress, ModifiedDate FROM {df}\n",
    "''', df = email_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS email_row_count FROM AdventureWorks.EmailAddress').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "080b0ce4-83fc-45ac-b5c5-01f60c70fffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|column_name      |data_type|\n",
      "+-----------------+---------+\n",
      "|BusinessEntityID |int      |\n",
      "|PhoneNumber      |string   |\n",
      "|PhoneNumberTypeID|int      |\n",
      "|ModifiedDate     |timestamp|\n",
      "+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Person.PersonPhone) t'\n",
    "phone_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(phone_df.dtypes, ['column_name', 'data_type']).show(phone_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5e60f0b-3bdc-4d81-8d82-8a09f75bb5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|database_name |table_name    |\n",
      "+--------------+--------------+\n",
      "|adventureworks|businessentity|\n",
      "|adventureworks|emailaddress  |\n",
      "|adventureworks|person        |\n",
      "|adventureworks|personphone   |\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.PersonPhone (\n",
    "    BusinessEntityID INT,\n",
    "    PhoneNumber STRING,\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Person/PersonPhone'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f130f993-30b7-4984-9818-be72c20ff055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|phone_row_count|\n",
      "+---------------+\n",
      "|19972          |\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.PersonPhone\n",
    "    SELECT BusinessEntityID, PhoneNumber, ModifiedDate FROM {df}\n",
    "''', df = phone_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS phone_row_count FROM AdventureWorks.PersonPhone').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2311de5-826f-49d3-a213-eac72f1c04eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>BusinessEntityID</th><th>PersonType</th><th>Title</th><th>FirstName</th><th>MiddleName</th><th>LastName</th><th>Suffix</th><th>EmailAddress</th><th>PhoneNumber</th></tr>\n",
       "<tr><td>1</td><td>EM</td><td>NULL</td><td>Ken</td><td>J</td><td>S&aacute;nchez</td><td>NULL</td><td>ken0@adventure-wo...</td><td>697-555-0142</td></tr>\n",
       "<tr><td>2</td><td>EM</td><td>NULL</td><td>Terri</td><td>Lee</td><td>Duffy</td><td>NULL</td><td>terri0@adventure-...</td><td>819-555-0175</td></tr>\n",
       "<tr><td>3</td><td>EM</td><td>NULL</td><td>Roberto</td><td>NULL</td><td>Tamburello</td><td>NULL</td><td>roberto0@adventur...</td><td>212-555-0187</td></tr>\n",
       "<tr><td>4</td><td>EM</td><td>NULL</td><td>Rob</td><td>NULL</td><td>Walters</td><td>NULL</td><td>rob0@adventure-wo...</td><td>612-555-0100</td></tr>\n",
       "<tr><td>5</td><td>EM</td><td>Ms.</td><td>Gail</td><td>A</td><td>Erickson</td><td>NULL</td><td>gail0@adventure-w...</td><td>849-555-0139</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----------------+----------+-----+---------+----------+----------+------+--------------------+------------+\n",
       "|BusinessEntityID|PersonType|Title|FirstName|MiddleName|  LastName|Suffix|        EmailAddress| PhoneNumber|\n",
       "+----------------+----------+-----+---------+----------+----------+------+--------------------+------------+\n",
       "|               1|        EM| NULL|      Ken|         J|   Sánchez|  NULL|ken0@adventure-wo...|697-555-0142|\n",
       "|               2|        EM| NULL|    Terri|       Lee|     Duffy|  NULL|terri0@adventure-...|819-555-0175|\n",
       "|               3|        EM| NULL|  Roberto|      NULL|Tamburello|  NULL|roberto0@adventur...|212-555-0187|\n",
       "|               4|        EM| NULL|      Rob|      NULL|   Walters|  NULL|rob0@adventure-wo...|612-555-0100|\n",
       "|               5|        EM|  Ms.|     Gail|         A|  Erickson|  NULL|gail0@adventure-w...|849-555-0139|\n",
       "+----------------+----------+-----+---------+----------+----------+------+--------------------+------------+"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_query = '''\n",
    "SELECT\n",
    "    be.BusinessEntityID,\n",
    "    p.PersonType,\n",
    "    p.Title,\n",
    "    p.FirstName,\n",
    "    p.MiddleName,\n",
    "    p.LastName,\n",
    "    p.Suffix,\n",
    "    ea.EmailAddress,\n",
    "    pp.PhoneNumber\n",
    "FROM AdventureWorks.BusinessEntity be \n",
    "INNER JOIN AdventureWorks.Person p ON be.BusinessEntityID = p.BusinessEntityID\n",
    "INNER JOIN AdventureWorks.EmailAddress ea ON ea.BusinessEntityID = be.BusinessEntityID \n",
    "INNER JOIN AdventureWorks.PersonPhone pp ON pp.BusinessEntityID = be.BusinessEntityID\n",
    "'''\n",
    "\n",
    "spark.sql(flat_query).limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd4f0928-c45f-4bba-874a-9765670503c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+\n",
      "|column_name          |data_type    |\n",
      "+---------------------+-------------+\n",
      "|SalesOrderID         |int          |\n",
      "|SalesOrderDetailID   |int          |\n",
      "|CarrierTrackingNumber|string       |\n",
      "|OrderQty             |smallint     |\n",
      "|ProductID            |int          |\n",
      "|SpecialOfferID       |int          |\n",
      "|UnitPrice            |decimal(19,4)|\n",
      "|UnitPriceDiscount    |decimal(19,4)|\n",
      "|LineTotal            |decimal(38,6)|\n",
      "|rowguid              |string       |\n",
      "|ModifiedDate         |timestamp    |\n",
      "+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Sales.SalesOrderDetail) t'\n",
    "sod_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(sod_df.dtypes, ['column_name', 'data_type']).show(sod_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "130a3a92-6e13-42fe-9503-91587752cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|database_name |table_name      |\n",
      "+--------------+----------------+\n",
      "|adventureworks|businessentity  |\n",
      "|adventureworks|emailaddress    |\n",
      "|adventureworks|person          |\n",
      "|adventureworks|personphone     |\n",
      "|adventureworks|salesorderdetail|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.SalesOrderDetail (\n",
    "    SalesOrderDetailID INT,\n",
    "    SalesOrderID INT,\n",
    "    OrderQty SMALLINT,\n",
    "    ProductID INT,\n",
    "    UnitPrice DECIMAL(19,4),\n",
    "    UnitPriceDiscount DECIMAL(19,4),\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Sales/SalesOrderDetail'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe849e60-b736-4d1b-85d6-9fd9ff86c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|sod_row_count|\n",
      "+-------------+\n",
      "|121317       |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.SalesOrderDetail\n",
    "    SELECT SalesOrderDetailID, SalesOrderID, OrderQty, ProductID, UnitPrice, UnitPriceDiscount, ModifiedDate\n",
    "    FROM {df}\n",
    "''', df = sod_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS sod_row_count FROM AdventureWorks.SalesOrderDetail').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfce5887-0399-4b3b-a485-9c024a72988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------+\n",
      "|column_name           |data_type    |\n",
      "+----------------------+-------------+\n",
      "|SalesOrderID          |int          |\n",
      "|RevisionNumber        |int          |\n",
      "|OrderDate             |timestamp    |\n",
      "|DueDate               |timestamp    |\n",
      "|ShipDate              |timestamp    |\n",
      "|Status                |int          |\n",
      "|OnlineOrderFlag       |boolean      |\n",
      "|SalesOrderNumber      |string       |\n",
      "|PurchaseOrderNumber   |string       |\n",
      "|AccountNumber         |string       |\n",
      "|CustomerID            |int          |\n",
      "|SalesPersonID         |int          |\n",
      "|TerritoryID           |int          |\n",
      "|BillToAddressID       |int          |\n",
      "|ShipToAddressID       |int          |\n",
      "|ShipMethodID          |int          |\n",
      "|CreditCardID          |int          |\n",
      "|CreditCardApprovalCode|string       |\n",
      "|CurrencyRateID        |int          |\n",
      "|SubTotal              |decimal(19,4)|\n",
      "|TaxAmt                |decimal(19,4)|\n",
      "|Freight               |decimal(19,4)|\n",
      "|TotalDue              |decimal(19,4)|\n",
      "|Comment               |string       |\n",
      "|rowguid               |string       |\n",
      "|ModifiedDate          |timestamp    |\n",
      "+----------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Sales.SalesOrderHeader) t'\n",
    "soh_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(soh_df.dtypes, ['column_name', 'data_type']).show(soh_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64a32246-9656-48c1-b4b3-de736bf1b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|database_name |table_name      |\n",
      "+--------------+----------------+\n",
      "|adventureworks|businessentity  |\n",
      "|adventureworks|emailaddress    |\n",
      "|adventureworks|person          |\n",
      "|adventureworks|personphone     |\n",
      "|adventureworks|salesorderdetail|\n",
      "|adventureworks|salesorderheader|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.SalesOrderHeader (\n",
    "    SalesOrderID INT,\n",
    "    OrderDate TIMESTAMP,\n",
    "    ShipDate TIMESTAMP,\n",
    "    DueDate TIMESTAMP,\n",
    "    OnlineOrderFlag BOOLEAN,\n",
    "    CustomerID INT,\n",
    "    TerritoryID INT,\n",
    "    TaxAmt DECIMAL(19,4),\n",
    "    Freight DECIMAL(19,4),\n",
    "    TotalDue DECIMAL(19,4),\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Sales/SalesOrderHeader'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8f317f5-8bee-4f8f-8959-8689a1cb2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|soh_row_count|\n",
      "+-------------+\n",
      "|31465        |\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.SalesOrderHeader\n",
    "    SELECT\n",
    "        SalesOrderID, OrderDate, ShipDate, DueDate, OnlineOrderFlag, CustomerID, TerritoryID, TaxAmt, Freight, TotalDue, ModifiedDate\n",
    "    FROM {df}\n",
    "''', df = soh_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS soh_row_count FROM AdventureWorks.SalesOrderHeader').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "493abc33-8de6-4fdb-98c9-0c3db12770eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|column_name  |data_type|\n",
      "+-------------+---------+\n",
      "|CustomerID   |int      |\n",
      "|PersonID     |int      |\n",
      "|StoreID      |int      |\n",
      "|TerritoryID  |int      |\n",
      "|AccountNumber|string   |\n",
      "|rowguid      |string   |\n",
      "|ModifiedDate |timestamp|\n",
      "+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Sales.Customer) t'\n",
    "customer_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(customer_df.dtypes, ['column_name', 'data_type']).show(customer_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9984e010-e6d0-4624-b892-f322ac99b924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|database_name |table_name      |\n",
      "+--------------+----------------+\n",
      "|adventureworks|businessentity  |\n",
      "|adventureworks|customer        |\n",
      "|adventureworks|emailaddress    |\n",
      "|adventureworks|person          |\n",
      "|adventureworks|personphone     |\n",
      "|adventureworks|salesorderdetail|\n",
      "|adventureworks|salesorderheader|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.Customer (\n",
    "    CustomerID INT,\n",
    "    PersonID INT,\n",
    "    StoreID INT,\n",
    "    TerritoryID INT,\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Sales/Customer'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7702b93a-55e6-490f-917b-084bb29d42d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|customer_row_count|\n",
      "+------------------+\n",
      "|19820             |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.Customer\n",
    "    SELECT CustomerID, PersonID, StoreID, TerritoryID, ModifiedDate FROM {df}\n",
    "''', df = customer_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS customer_row_count FROM AdventureWorks.Customer').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2593c1ad-22c6-450c-bd93-a1f272a582b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>OrderDate</th><th>CustomerID</th><th>TerritoryID</th><th>ProductID</th><th>OrderQty</th><th>UnitPrice</th></tr>\n",
       "<tr><td>2011-05-31 00:00:00</td><td>29825</td><td>5</td><td>776</td><td>1</td><td>2024.9940</td></tr>\n",
       "<tr><td>2011-05-31 00:00:00</td><td>29825</td><td>5</td><td>777</td><td>3</td><td>2024.9940</td></tr>\n",
       "<tr><td>2011-05-31 00:00:00</td><td>29825</td><td>5</td><td>778</td><td>1</td><td>2024.9940</td></tr>\n",
       "<tr><td>2011-05-31 00:00:00</td><td>29825</td><td>5</td><td>771</td><td>1</td><td>2039.9940</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------------+----------+-----------+---------+--------+---------+\n",
       "|          OrderDate|CustomerID|TerritoryID|ProductID|OrderQty|UnitPrice|\n",
       "+-------------------+----------+-----------+---------+--------+---------+\n",
       "|2011-05-31 00:00:00|     29825|          5|      776|       1|2024.9940|\n",
       "|2011-05-31 00:00:00|     29825|          5|      777|       3|2024.9940|\n",
       "|2011-05-31 00:00:00|     29825|          5|      778|       1|2024.9940|\n",
       "|2011-05-31 00:00:00|     29825|          5|      771|       1|2039.9940|\n",
       "+-------------------+----------+-----------+---------+--------+---------+"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_query = '''\n",
    "SELECT\n",
    "    soh.OrderDate, soh.CustomerID, soh.TerritoryID, sod.ProductID, sod.OrderQty, sod.UnitPrice \n",
    "FROM AdventureWorks.SalesOrderHeader soh \n",
    "INNER JOIN AdventureWorks.SalesOrderDetail sod ON soh.SalesOrderID = sod.SalesOrderID \n",
    "INNER JOIN AdventureWorks.Customer c ON c.CustomerID = soh.CustomerID \n",
    "'''\n",
    "\n",
    "spark.sql(flat_query).limit(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14ea9410-768a-4496-99b2-5eb53104c029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+\n",
      "|column_name          |data_type    |\n",
      "+---------------------+-------------+\n",
      "|ProductID            |int          |\n",
      "|Name                 |string       |\n",
      "|ProductNumber        |string       |\n",
      "|MakeFlag             |boolean      |\n",
      "|FinishedGoodsFlag    |boolean      |\n",
      "|Color                |string       |\n",
      "|SafetyStockLevel     |smallint     |\n",
      "|ReorderPoint         |smallint     |\n",
      "|StandardCost         |decimal(19,4)|\n",
      "|ListPrice            |decimal(19,4)|\n",
      "|Size                 |string       |\n",
      "|SizeUnitMeasureCode  |string       |\n",
      "|WeightUnitMeasureCode|string       |\n",
      "|Weight               |decimal(8,2) |\n",
      "|DaysToManufacture    |int          |\n",
      "|ProductLine          |string       |\n",
      "|Class                |string       |\n",
      "|Style                |string       |\n",
      "|ProductSubcategoryID |int          |\n",
      "|ProductModelID       |int          |\n",
      "|SellStartDate        |timestamp    |\n",
      "|SellEndDate          |timestamp    |\n",
      "|DiscontinuedDate     |timestamp    |\n",
      "|rowguid              |string       |\n",
      "|ModifiedDate         |timestamp    |\n",
      "+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Production.Product) t'\n",
    "product_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(product_df.dtypes, ['column_name', 'data_type']).show(product_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81eae63d-990f-45fb-915e-916b88b45394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|database_name |table_name      |\n",
      "+--------------+----------------+\n",
      "|adventureworks|businessentity  |\n",
      "|adventureworks|customer        |\n",
      "|adventureworks|emailaddress    |\n",
      "|adventureworks|person          |\n",
      "|adventureworks|personphone     |\n",
      "|adventureworks|product         |\n",
      "|adventureworks|salesorderdetail|\n",
      "|adventureworks|salesorderheader|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.Product (\n",
    "    ProductID INT,\n",
    "    ProductSubcategoryID INT,\n",
    "    Name STRING,\n",
    "    Color STRING,\n",
    "    ListPrice DECIMAL(19,4),\n",
    "    Size STRING,\n",
    "    Weight DECIMAL(8,2),\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Production/Product'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e2af065-0f5b-4231-83e5-7d2279956195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|product_row_count|\n",
      "+-----------------+\n",
      "|504              |\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.Product\n",
    "    SELECT ProductID, ProductSubcategoryID, Name, Color, ListPrice, Size, Weight, ModifiedDate FROM {df}\n",
    "''', df = product_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS product_row_count FROM AdventureWorks.Product').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1337ae0-4bb3-4f93-b51b-e40355d377cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+\n",
      "|column_name      |data_type|\n",
      "+-----------------+---------+\n",
      "|ProductCategoryID|int      |\n",
      "|Name             |string   |\n",
      "|rowguid          |string   |\n",
      "|ModifiedDate     |timestamp|\n",
      "+-----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Production.ProductCategory) t'\n",
    "category_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(category_df.dtypes, ['column_name', 'data_type']).show(category_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9a91d86-863a-4163-87fa-cebd73d9e45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------+\n",
      "|database_name |table_name      |\n",
      "+--------------+----------------+\n",
      "|adventureworks|businessentity  |\n",
      "|adventureworks|customer        |\n",
      "|adventureworks|emailaddress    |\n",
      "|adventureworks|person          |\n",
      "|adventureworks|personphone     |\n",
      "|adventureworks|product         |\n",
      "|adventureworks|productcategory |\n",
      "|adventureworks|salesorderdetail|\n",
      "|adventureworks|salesorderheader|\n",
      "+--------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.ProductCategory (\n",
    "    ProductCategoryID INT,\n",
    "    Name STRING,\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Production/ProductCategory'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02222696-b8af-45c5-91a2-7d75cb537b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|category_row_count|\n",
      "+------------------+\n",
      "|4                 |\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.ProductCategory\n",
    "    SELECT ProductCategoryID, Name, ModifiedDate FROM {df}\n",
    "''', df = category_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS category_row_count FROM AdventureWorks.ProductCategory').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f24c1c44-c805-4c56-a9b2-9729221587b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|column_name         |data_type|\n",
      "+--------------------+---------+\n",
      "|ProductSubcategoryID|int      |\n",
      "|ProductCategoryID   |int      |\n",
      "|Name                |string   |\n",
      "|rowguid             |string   |\n",
      "|ModifiedDate        |timestamp|\n",
      "+--------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qryStr = '(SELECT * FROM Production.ProductSubcategory) t'\n",
    "subcategory_df = spark.read.format('jdbc').option('dbtable', qryStr ).options(**jdbc_options).load()\n",
    "spark.createDataFrame(subcategory_df.dtypes, ['column_name', 'data_type']).show(subcategory_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ac22992-8fc7-468c-8cfc-bc36b9fc3020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|database_name |table_name        |\n",
      "+--------------+------------------+\n",
      "|adventureworks|businessentity    |\n",
      "|adventureworks|customer          |\n",
      "|adventureworks|emailaddress      |\n",
      "|adventureworks|person            |\n",
      "|adventureworks|personphone       |\n",
      "|adventureworks|product           |\n",
      "|adventureworks|productcategory   |\n",
      "|adventureworks|productsubcategory|\n",
      "|adventureworks|salesorderdetail  |\n",
      "|adventureworks|salesorderheader  |\n",
      "+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS AdventureWorks.ProductSubcategory (\n",
    "    ProductSubcategoryID INT,\n",
    "    ProductCategoryID INT,\n",
    "    Name STRING,\n",
    "    ModifiedDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/bronze/AdventureWorks/Production/ProductSubcategory'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN AdventureWorks')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "029bcc6a-4336-4647-9f08-349bb603edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|subcategory_row_count|\n",
      "+---------------------+\n",
      "|37                   |\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO AdventureWorks.ProductSubcategory\n",
    "    SELECT ProductSubcategoryID, ProductCategoryID, Name, ModifiedDate FROM {df}\n",
    "''', df = subcategory_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS subcategory_row_count FROM AdventureWorks.ProductSubcategory').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85ec3ad5-58bd-4789-a9b9-c982e80cad03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>CategoryName</th><th>SubCategoryName</th><th>ProductName</th><th>Color</th><th>Size</th><th>Weight</th></tr>\n",
       "<tr><td>Bikes</td><td>Mountain Bikes</td><td>Mountain-500 Blac...</td><td>Black</td><td>52</td><td>28.68</td></tr>\n",
       "<tr><td>Bikes</td><td>Mountain Bikes</td><td>Mountain-500 Blac...</td><td>Black</td><td>48</td><td>28.42</td></tr>\n",
       "<tr><td>Bikes</td><td>Mountain Bikes</td><td>Mountain-500 Blac...</td><td>Black</td><td>44</td><td>28.13</td></tr>\n",
       "<tr><td>Bikes</td><td>Mountain Bikes</td><td>Mountain-500 Blac...</td><td>Black</td><td>42</td><td>27.77</td></tr>\n",
       "<tr><td>Bikes</td><td>Mountain Bikes</td><td>Mountain-500 Blac...</td><td>Black</td><td>40</td><td>27.35</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+------------+---------------+--------------------+-----+----+------+\n",
       "|CategoryName|SubCategoryName|         ProductName|Color|Size|Weight|\n",
       "+------------+---------------+--------------------+-----+----+------+\n",
       "|       Bikes| Mountain Bikes|Mountain-500 Blac...|Black|  52| 28.68|\n",
       "|       Bikes| Mountain Bikes|Mountain-500 Blac...|Black|  48| 28.42|\n",
       "|       Bikes| Mountain Bikes|Mountain-500 Blac...|Black|  44| 28.13|\n",
       "|       Bikes| Mountain Bikes|Mountain-500 Blac...|Black|  42| 27.77|\n",
       "|       Bikes| Mountain Bikes|Mountain-500 Blac...|Black|  40| 27.35|\n",
       "+------------+---------------+--------------------+-----+----+------+"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_query = '''\n",
    "SELECT\n",
    "    pc.Name as CategoryName,\n",
    "    ps.Name as SubCategoryName,\n",
    "    p.Name as ProductName,\n",
    "    p.Color,\n",
    "    p.Size,\n",
    "    p.Weight \n",
    "FROM AdventureWorks.ProductCategory pc \n",
    "INNER JOIN AdventureWorks.ProductSubcategory ps ON pc.ProductCategoryID = ps.ProductCategoryID \n",
    "INNER JOIN AdventureWorks.Product p ON p.ProductSubcategoryID = ps.ProductSubcategoryID \n",
    "'''\n",
    "\n",
    "spark.sql(flat_query).limit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675044c-ceb1-4b87-8fa7-5a1ac17055bd",
   "metadata": {},
   "source": [
    "## Perform more complex queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bca96fb0-99d2-4de4-833d-e1398ba3ba43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+-------------------+-----------------+\n",
      "|CustomerID|FirstOrderDate     |SecondOrderDate    |DaysBetweenOrders|\n",
      "+----------+-------------------+-------------------+-----------------+\n",
      "|11015     |2013-06-20 00:00:00|2013-06-20 00:00:00|0                |\n",
      "|11016     |2013-07-12 00:00:00|2013-07-12 00:00:00|0                |\n",
      "|11019     |2013-07-15 00:00:00|2013-08-04 00:00:00|20               |\n",
      "|11020     |2013-05-31 00:00:00|2013-05-31 00:00:00|0                |\n",
      "|11021     |2013-06-25 00:00:00|2013-06-25 00:00:00|0                |\n",
      "|11022     |2013-06-22 00:00:00|2013-06-22 00:00:00|0                |\n",
      "|11024     |2013-11-27 00:00:00|2013-12-26 00:00:00|29               |\n",
      "+----------+-------------------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# مشتریانی که بین اولین و دومین سفارششان، کمتر از ۱ ماه طول کشیده باشد\n",
    "\n",
    "query = '''\n",
    "WITH CustomerFirstTwoOrders AS (\n",
    "    SELECT \n",
    "        CustomerID,\n",
    "        OrderDate,\n",
    "        ROW_NUMBER() OVER (PARTITION BY CustomerID ORDER BY OrderDate) AS RowNum\n",
    "    FROM AdventureWorks.SalesOrderHeader\n",
    ")\n",
    "SELECT \n",
    "    c.CustomerID,\n",
    "    MIN(f.OrderDate) AS FirstOrderDate,\n",
    "    MAX(f.OrderDate) AS SecondOrderDate,\n",
    "    DATEDIFF(DAY, MIN(f.OrderDate), MAX(f.OrderDate)) AS DaysBetweenOrders\n",
    "FROM CustomerFirstTwoOrders f\n",
    "INNER JOIN AdventureWorks.Customer c ON f.CustomerID = c.CustomerID\n",
    "WHERE f.RowNum <= 2\n",
    "GROUP BY c.CustomerID\n",
    "HAVING DATEDIFF(DAY, MIN(f.OrderDate), MAX(f.OrderDate)) < 31;\n",
    "'''\n",
    "\n",
    "spark.sql(query).limit(7).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049b6c3a-9689-4f37-ae5c-97dde9e763a2",
   "metadata": {},
   "source": [
    "## Work with files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eedc36cc-cb05-40bc-a0b6-2248d1ea3cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|current_database|\n",
      "+----------------+\n",
      "|otherdb         |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('USE OtherDB')\n",
    "spark.sql('SELECT current_schema() AS current_database').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20a710dd-1f6f-4140-9057-b5f7ea6fcf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+---------+\n",
      "|column_name                |data_type|\n",
      "+---------------------------+---------+\n",
      "|_c0                        |int      |\n",
      "|arrest_key                 |int      |\n",
      "|arrest_date                |date     |\n",
      "|pd_desc                    |string   |\n",
      "|ofns_desc                  |string   |\n",
      "|law_code                   |string   |\n",
      "|law_cat_cd                 |string   |\n",
      "|age_group                  |string   |\n",
      "|perp_sex                   |string   |\n",
      "|perp_race                  |string   |\n",
      "|latitude                   |double   |\n",
      "|longitude                  |double   |\n",
      "|arrest_boro                |string   |\n",
      "|arrest_precinct            |int      |\n",
      "|jurisdiction_code          |double   |\n",
      "|:@computed_region_f5dn_yrer|double   |\n",
      "|:@computed_region_yeji_bk3q|double   |\n",
      "|:@computed_region_92fq_4b7q|double   |\n",
      "|:@computed_region_sbqj_enih|double   |\n",
      "+---------------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crime_df = spark.read.option('header', 'true').option('inferSchema', 'true').option('delimiter', ',').csv('../../data/crime.csv')\n",
    "spark.createDataFrame(crime_df.dtypes, ['column_name', 'data_type']).show(crime_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1427b68b-b1c5-4de3-b34e-ad52f5592c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>arrest_date</th><th>pd_desc</th><th>ofns_desc</th><th>age_group</th><th>perp_sex</th><th>perp_race</th><th>latitude</th><th>longitude</th></tr>\n",
       "<tr><td>2019-01-26</td><td>SEXUAL ABUSE</td><td>SEX CRIMES</td><td>45-64</td><td>M</td><td>BLACK</td><td>40.800694331000045</td><td>-73.94110928599997</td></tr>\n",
       "<tr><td>2019-02-06</td><td>CRIMINAL SALE OF ...</td><td>CONTROLLED SUBSTA...</td><td>25-44</td><td>M</td><td>UNKNOWN</td><td>40.75783900300007</td><td>-73.99121211099998</td></tr>\n",
       "<tr><td>2016-01-06</td><td>RAPE 3</td><td>RAPE</td><td>25-44</td><td>M</td><td>BLACK</td><td>40.648650085000035</td><td>-73.95033556299995</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------------------+--------------------+---------+--------+---------+------------------+------------------+\n",
       "|arrest_date|             pd_desc|           ofns_desc|age_group|perp_sex|perp_race|          latitude|         longitude|\n",
       "+-----------+--------------------+--------------------+---------+--------+---------+------------------+------------------+\n",
       "| 2019-01-26|        SEXUAL ABUSE|          SEX CRIMES|    45-64|       M|    BLACK|40.800694331000045|-73.94110928599997|\n",
       "| 2019-02-06|CRIMINAL SALE OF ...|CONTROLLED SUBSTA...|    25-44|       M|  UNKNOWN| 40.75783900300007|-73.99121211099998|\n",
       "| 2016-01-06|              RAPE 3|                RAPE|    25-44|       M|    BLACK|40.648650085000035|-73.95033556299995|\n",
       "+-----------+--------------------+--------------------+---------+--------+---------+------------------+------------------+"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT\n",
    "        arrest_date, pd_desc, ofns_desc, age_group, perp_sex, perp_race, latitude, longitude\n",
    "    FROM {df}\n",
    "    LIMIT 3\n",
    "''', df = crime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec4bd933-061e-46c3-a566-f8bd32f04bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>description</th><th>age_group</th><th>gender</th><th>latitude</th><th>longitude</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>SEX CRIMES</td><td>45-64</td><td>Male</td><td>40.800694331000045</td><td>-73.94110928599997</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>CONTROLLED SUBSTA...</td><td>25-44</td><td>Male</td><td>40.75783900300007</td><td>-73.99121211099998</td></tr>\n",
       "<tr><td>2016</td><td>1</td><td>RAPE</td><td>25-44</td><td>Male</td><td>40.648650085000035</td><td>-73.95033556299995</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+--------------------+---------+------+------------------+------------------+\n",
       "|year|month|         description|age_group|gender|          latitude|         longitude|\n",
       "+----+-----+--------------------+---------+------+------------------+------------------+\n",
       "|2019|    1|          SEX CRIMES|    45-64|  Male|40.800694331000045|-73.94110928599997|\n",
       "|2019|    2|CONTROLLED SUBSTA...|    25-44|  Male| 40.75783900300007|-73.99121211099998|\n",
       "|2016|    1|                RAPE|    25-44|  Male|40.648650085000035|-73.95033556299995|\n",
       "+----+-----+--------------------+---------+------+------------------+------------------+"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT\n",
    "        YEAR(arrest_date) AS year,\n",
    "        MONTH(arrest_date) AS month,\n",
    "        COALESCE(ofns_desc, Null) AS description,\n",
    "        COALESCE(age_group, Null) AS age_group,\n",
    "        CASE\n",
    "            WHEN perp_sex = 'M' THEN 'Male' \n",
    "            WHEN perp_sex = 'F' THEN 'Female' \n",
    "        ELSE Null END AS gender,\n",
    "        latitude,\n",
    "        longitude\n",
    "    FROM {df}\n",
    "    LIMIT 3\n",
    "''', df = crime_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4c89bdf-5139-480a-84d2-3781b03a4585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|database_name|table_name|\n",
      "+-------------+----------+\n",
      "|otherdb      |crime     |\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS crime (\n",
    "    arrest_date DATE,\n",
    "    pd_desc STRING,\n",
    "    ofns_desc STRING,\n",
    "    age_group STRING,\n",
    "    perp_sex STRING,\n",
    "    perp_race STRING,\n",
    "    latitude DOUBLE,\n",
    "    longitude DOUBLE\n",
    ") USING DELTA LOCATION '../lake/bronze/OtherDB/crime'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN OtherDB')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b8b5b7c-8197-429d-b06f-3b8a7d279aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|crime_row_count|\n",
      "+---------------+\n",
      "|3881989        |\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO crime\n",
    "    SELECT arrest_date, pd_desc, ofns_desc, age_group, perp_sex, perp_race, latitude, longitude FROM {df} ''', df = crime_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS crime_row_count FROM crime').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "10320460-681e-4552-a26d-496285adb0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+\n",
      "|database_name|view_name|\n",
      "+-------------+---------+\n",
      "|otherdb      |vw_crime |\n",
      "+-------------+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>year</th><th>month</th><th>description</th><th>age_group</th><th>gender</th><th>latitude</th><th>longitude</th></tr>\n",
       "<tr><td>2019</td><td>1</td><td>SEX CRIMES</td><td>45-64</td><td>Male</td><td>40.800694331000045</td><td>-73.94110928599997</td></tr>\n",
       "<tr><td>2019</td><td>2</td><td>CONTROLLED SUBSTA...</td><td>25-44</td><td>Male</td><td>40.75783900300007</td><td>-73.99121211099998</td></tr>\n",
       "<tr><td>2016</td><td>1</td><td>RAPE</td><td>25-44</td><td>Male</td><td>40.648650085000035</td><td>-73.95033556299995</td></tr>\n",
       "<tr><td>2018</td><td>11</td><td>RAPE</td><td>25-44</td><td>Male</td><td>40.67458330800008</td><td>-73.93022154099998</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+----+-----+--------------------+---------+------+------------------+------------------+\n",
       "|year|month|         description|age_group|gender|          latitude|         longitude|\n",
       "+----+-----+--------------------+---------+------+------------------+------------------+\n",
       "|2019|    1|          SEX CRIMES|    45-64|  Male|40.800694331000045|-73.94110928599997|\n",
       "|2019|    2|CONTROLLED SUBSTA...|    25-44|  Male| 40.75783900300007|-73.99121211099998|\n",
       "|2016|    1|                RAPE|    25-44|  Male|40.648650085000035|-73.95033556299995|\n",
       "|2018|   11|                RAPE|    25-44|  Male| 40.67458330800008|-73.93022154099998|\n",
       "+----+-----+--------------------+---------+------+------------------+------------------+"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE OR REPLACE VIEW vw_crime AS\n",
    "    SELECT\n",
    "        YEAR(arrest_date) AS year,\n",
    "        MONTH(arrest_date) AS month,\n",
    "        COALESCE(ofns_desc, Null) AS description,\n",
    "        COALESCE(age_group, Null) AS age_group,\n",
    "        CASE \n",
    "            WHEN perp_sex = 'M' THEN 'Male' \n",
    "            WHEN perp_sex = 'F' THEN 'Female' \n",
    "        ELSE Null END AS gender,\n",
    "        latitude,\n",
    "        longitude\n",
    "    FROM crime\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, viewName as view_name FROM {df}', df = spark.sql('SHOW VIEWS IN OtherDB')).show(truncate=False)\n",
    "spark.sql('SELECT * FROM vw_crime LIMIT 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762765f-0ca4-40a4-b34b-b3eb567488a3",
   "metadata": {},
   "source": [
    "## Query all files inside a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fca4d2c5-e418-42be-b228-887c65565d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df = spark.read.parquet('../../data/trip/*/*.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb5f515e-9233-4284-8efa-ebb24dfa4ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count_rides|\n",
      "+-----------+\n",
      "|565621687  |\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT COUNT(*) count_rides FROM {df}', df = trip_df).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04f9ac11-995f-4ba0-8a18-e1ec4395c02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>tpep_pickup_datetime</th><th>tpep_dropoff_datetime</th><th>passenger_count</th><th>trip_distance</th><th>payment_type</th><th>fare_amount</th><th>mta_tax</th><th>tip_amount</th><th>tolls_amount</th><th>total_amount</th></tr>\n",
       "<tr><td>2016-01-01 00:12:22</td><td>2016-01-01 00:29:14</td><td>1</td><td>3.2</td><td>1</td><td>14.0</td><td>0.5</td><td>3.06</td><td>0.0</td><td>18.36</td></tr>\n",
       "<tr><td>2016-01-01 00:41:31</td><td>2016-01-01 00:55:10</td><td>2</td><td>1.0</td><td>2</td><td>9.5</td><td>0.5</td><td>0.0</td><td>0.0</td><td>10.8</td></tr>\n",
       "<tr><td>2016-01-01 00:53:37</td><td>2016-01-01 00:59:57</td><td>1</td><td>0.9</td><td>2</td><td>6.0</td><td>0.5</td><td>0.0</td><td>0.0</td><td>7.3</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+---------------------+---------------+-------------+------------+-----------+-------+----------+------------+------------+\n",
       "|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|payment_type|fare_amount|mta_tax|tip_amount|tolls_amount|total_amount|\n",
       "+--------------------+---------------------+---------------+-------------+------------+-----------+-------+----------+------------+------------+\n",
       "| 2016-01-01 00:12:22|  2016-01-01 00:29:14|              1|          3.2|           1|       14.0|    0.5|      3.06|         0.0|       18.36|\n",
       "| 2016-01-01 00:41:31|  2016-01-01 00:55:10|              2|          1.0|           2|        9.5|    0.5|       0.0|         0.0|        10.8|\n",
       "| 2016-01-01 00:53:37|  2016-01-01 00:59:57|              1|          0.9|           2|        6.0|    0.5|       0.0|         0.0|         7.3|\n",
       "+--------------------+---------------------+---------------+-------------+------------+-----------+-------+----------+------------+------------+"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT\n",
    "        tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, payment_type, fare_amount, mta_tax, tip_amount, tolls_amount, total_amount\n",
    "    FROM {df}\n",
    "    LIMIT 3\n",
    "''', df = trip_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96632d44-8b8a-40ce-8000-b54d606412ea",
   "metadata": {},
   "source": [
    "## Use DuckDB to safely bring multiple files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4049705-33b8-46e1-b58f-7fc679ae1e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_row_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>565621687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_row_count\n",
       "0       565621687"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "conn = duckdb.connect('../temp/tempdb.duckdb')\n",
    "conn.sql('''\n",
    "    SELECT COUNT(*) AS trip_row_count FROM read_parquet('../../data/trip/*/*.parquet')\n",
    "''').df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ddc1d0b3-8c71-46a8-8e89-1c5717055437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48dabd051fc411db3ee369f13d44c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE OR REPLACE TABLE trip AS\n",
    "    SELECT\n",
    "        tpep_pickup_datetime,\n",
    "        tpep_dropoff_datetime,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        payment_type,\n",
    "        fare_amount,\n",
    "        mta_tax,\n",
    "        tip_amount,\n",
    "        tolls_amount,\n",
    "        total_amount\n",
    "    FROM read_parquet('../../data/trip/*/*.parquet')\n",
    "'''\n",
    "\n",
    "conn.sql(sql)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a1e58e17-af85-479a-9b22-5fc274e5cdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64ce41acffc4b10ba71d76efbff5809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = duckdb.connect('../temp/tempdb.duckdb')\n",
    "conn.sql('COPY trip TO \"../temp/trip.parquet\" (FORMAT PARQUET)')\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87047535-2512-4645-8c2f-ae887ccc9b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+\n",
      "|column_name          |data_type    |\n",
      "+---------------------+-------------+\n",
      "|tpep_pickup_datetime |timestamp_ntz|\n",
      "|tpep_dropoff_datetime|timestamp_ntz|\n",
      "|passenger_count      |bigint       |\n",
      "|trip_distance        |double       |\n",
      "|payment_type         |bigint       |\n",
      "|fare_amount          |double       |\n",
      "|mta_tax              |double       |\n",
      "|tip_amount           |double       |\n",
      "|tolls_amount         |double       |\n",
      "|total_amount         |double       |\n",
      "+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_df = spark.read.parquet('../temp/trip.parquet')\n",
    "spark.createDataFrame(trip_df.dtypes, ['column_name', 'data_type']).show(trip_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b62559fb-3fc2-4fac-970b-8af124cbdfe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|database_name|table_name|\n",
      "+-------------+----------+\n",
      "|otherdb      |crime     |\n",
      "|otherdb      |trip      |\n",
      "|otherdb      |vw_crime  |\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# partition table for larger datasets\n",
    "\n",
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS trip (\n",
    "    tpep_pickup_datetime TIMESTAMP_NTZ,\n",
    "    tpep_dropoff_datetime TIMESTAMP_NTZ,\n",
    "    passenger_count BIGINT,\n",
    "    trip_distance DOUBLE,\n",
    "    payment_type BIGINT,\n",
    "    fare_amount DOUBLE,\n",
    "    mta_tax DOUBLE,\n",
    "    tip_amount DOUBLE,\n",
    "    tolls_amount DOUBLE,\n",
    "    total_amount DOUBLE\n",
    ") USING DELTA LOCATION '../lake/bronze/OtherDB/trip' PARTITIONED BY (payment_type)\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN OtherDB')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "563527a8-7fd9-41c7-97c3-bc9d1d86cfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|trip_row_count|\n",
      "+--------------+\n",
      "|565621687     |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO trip\n",
    "    SELECT\n",
    "        tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, payment_type, fare_amount, mta_tax, tip_amount, tolls_amount, total_amount\n",
    "    FROM {df}\n",
    "''', df = trip_df)\n",
    "\n",
    "spark.sql('SELECT COUNT(*) AS trip_row_count FROM OtherDB.trip').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41c56b7f-ace7-498b-8850-934e03d8a59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r ../temp/trip.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b8481d-06bf-47b9-8b2f-b51d98b5885d",
   "metadata": {},
   "source": [
    "## Fast query a delta table using DuckDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9fdf936f-4b67-4a76-a1c6-8af9597a5492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extension_name</th>\n",
       "      <th>installed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>delta</td>\n",
       "      <td>True</td>\n",
       "      <td>Adds support for Delta Lake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  extension_name  installed                  description\n",
       "0          delta       True  Adds support for Delta Lake"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import duckdb\n",
    "duckdb.sql('''SELECT extension_name, installed, description FROM duckdb_extensions() WHERE extension_name='delta' ''').df()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e8868f6-f618-492c-94a4-b4e616c53690",
   "metadata": {},
   "source": [
    "duckdb.sql('INSTALL DELTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b476c4af-5255-4219-adea-3dbf2a53833d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb49f17d04d476ea8043c239e117b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Payment type</th>\n",
       "      <th>Passengers Average</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.548711</td>\n",
       "      <td>7.722359e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.625162</td>\n",
       "      <td>2.371349e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.741566e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.261405</td>\n",
       "      <td>5.061590e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.305835</td>\n",
       "      <td>1.085476e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.116883</td>\n",
       "      <td>7.982000e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Payment type  Passengers Average        Amount\n",
       "0             1            1.548711  7.722359e+09\n",
       "1             2            1.625162  2.371349e+09\n",
       "2             0            0.000000  1.741566e+08\n",
       "3             3            1.261405  5.061590e+07\n",
       "4             4            1.305835  1.085476e+07\n",
       "5             5            1.116883  7.982000e+02"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql('LOAD DELTA')\n",
    "\n",
    "sql = '''\n",
    "SELECT\n",
    "    payment_type AS 'Payment type',\n",
    "    COALESCE(AVG(passenger_count), 0) AS 'Passengers Average',\n",
    "    COALESCE(SUM(total_amount), 0) AS Amount\n",
    "FROM delta_scan('../lake/bronze/OtherDB/trip/')\n",
    "GROUP BY payment_type\n",
    "ORDER BY 3 DESC, 2 DESC\n",
    "'''\n",
    "\n",
    "duckdb.sql(sql).df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4d20a85-d793-441b-bae6-ca14718fd10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|database_name|table_name      |\n",
      "+-------------+----------------+\n",
      "|otherdb      |crime           |\n",
      "|otherdb      |trip            |\n",
      "|otherdb      |vw_crime        |\n",
      "|otherdb      |vw_trip_duration|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE OR REPLACE VIEW vw_trip_duration AS\n",
    "    SELECT\n",
    "        total_amount as amount,\n",
    "        UNIX_TIMESTAMP(tpep_dropoff_datetime) - UNIX_TIMESTAMP(tpep_pickup_datetime) AS duration,\n",
    "        trip_distance as distance,\n",
    "        hour(tpep_pickup_datetime) as hour,\n",
    "        CAST(passenger_count AS INT) AS passenger,\n",
    "        payment_type as payment\n",
    "    FROM trip\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN OtherDB')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e538e950-8fa4-4b88-9ed4-71dfec71d53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+----+---------+-------+\n",
      "|amount|duration|distance|hour|passenger|payment|\n",
      "+------+--------+--------+----+---------+-------+\n",
      "|67.8  |3168    |22.0    |13  |1        |1      |\n",
      "|12.35 |363     |0.9     |15  |2        |1      |\n",
      "|12.3  |633     |0.8     |13  |1        |1      |\n",
      "+------+--------+--------+----+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM vw_trip_duration LIMIT 3').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb315fe-f907-48d9-8183-00f3a7e80f97",
   "metadata": {},
   "source": [
    "## Create view for reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3aec44b7-afce-4874-a608-96d52ca7bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|database_name|view_name       |\n",
      "+-------------+----------------+\n",
      "|otherdb      |vw_crime        |\n",
      "|otherdb      |vw_trip_duration|\n",
      "|otherdb      |vw_trip_report  |\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE OR REPLACE VIEW vw_trip_report AS\n",
    "    WITH trip AS (\n",
    "        SELECT\n",
    "            MONTH(tpep_pickup_datetime) AS month,\n",
    "            CAST(passenger_count AS INT) AS passenger_count,\n",
    "            payment_type,\n",
    "            UNIX_TIMESTAMP(tpep_dropoff_datetime) - UNIX_TIMESTAMP(tpep_pickup_datetime) AS duration\n",
    "    FROM trip\n",
    "    )\n",
    "    SELECT\n",
    "        CASE month\n",
    "            WHEN 1 THEN 'January'\n",
    "            WHEN 2 THEN 'February'\n",
    "            WHEN 3 THEN 'March'\n",
    "            WHEN 4 THEN 'April'\n",
    "            WHEN 5 THEN 'May'\n",
    "            WHEN 6 THEN 'June'\n",
    "            WHEN 7 THEN 'July'\n",
    "            WHEN 8 THEN 'August'\n",
    "            WHEN 9 THEN 'September'\n",
    "            WHEN 10 THEN 'October'\n",
    "            WHEN 11 THEN 'November'\n",
    "            WHEN 12 THEN 'December'\n",
    "        END AS month,\n",
    "        CASE payment_type\n",
    "            WHEN 0 THEN 'Cash'\n",
    "            WHEN 1 THEN 'Credit Card'\n",
    "            WHEN 2 THEN 'Debit Card'\n",
    "            WHEN 3 THEN 'Free of Charge'\n",
    "            ELSE 'Unknown'\n",
    "        END AS payment_type,\n",
    "        COALESCE(\n",
    "            SUM(passenger_count), 0\n",
    "        ) AS total_passenger_count\n",
    "    FROM trip\n",
    "    GROUP BY month, payment_type\n",
    "    ORDER BY total_passenger_count DESC\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, viewName as view_name FROM {df}', df = spark.sql('SHOW VIEWS IN OtherDB')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ffd9a10-17ce-43bd-b0ba-d37b59986485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------------------+\n",
      "|month    |payment_type|total_passenger_count|\n",
      "+---------+------------+---------------------+\n",
      "|March    |Credit Card |56547957             |\n",
      "|February |Credit Card |55005683             |\n",
      "|January  |Credit Card |54953193             |\n",
      "|October  |Credit Card |52828619             |\n",
      "|May      |Credit Card |52607317             |\n",
      "|April    |Credit Card |52167256             |\n",
      "|June     |Credit Card |50495234             |\n",
      "|November |Credit Card |49611323             |\n",
      "|December |Credit Card |49373428             |\n",
      "|September|Credit Card |47257834             |\n",
      "+---------+------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM vw_trip_report LIMIT 10').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2737893-243d-4e30-979d-e788f9a5e501",
   "metadata": {},
   "source": [
    "## Data Quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0da7d96b-a48f-4303-a416-dc1ea0fab3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_df = spark.sql('SELECT * FROM OtherDB.trip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d2fb458a-5b8b-48b4-9bb2-f4280edee1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+-------------------+---------------------+\n",
      "|entity     |instance               |name               |value                |\n",
      "+-----------+-----------------------+-------------------+---------------------+\n",
      "|Multicolumn|payment_type,tip_amount|Correlation        |-3.518101135256185E-4|\n",
      "|Column     |tpep_pickup_datetime   |Completeness       |1.0                  |\n",
      "|Column     |more-5 passenger_count |Compliance         |0.06527827848298186  |\n",
      "|Dataset    |*                      |Size               |5.65621687E8         |\n",
      "|Column     |payment_type           |ApproxCountDistinct|6.0                  |\n",
      "|Column     |passenger_count        |Mean               |1.5685495143314883   |\n",
      "|Column     |less-0 passenger_count |Compliance         |0.009154656051934586 |\n",
      "+-----------+-----------------------+-------------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morteza/Documents/deltastudio/venv/lib/python3.12/site-packages/pyspark/sql/dataframe.py:147: UserWarning: DataFrame constructor is internal. Do not directly use it.\n",
      "  warnings.warn(\"DataFrame constructor is internal. Do not directly use it.\")\n"
     ]
    }
   ],
   "source": [
    "analysisResult = AnalysisRunner(spark) \\\n",
    "                    .onData(trip_df) \\\n",
    "                    .addAnalyzer(Size()) \\\n",
    "                    .addAnalyzer(Completeness('tpep_pickup_datetime')) \\\n",
    "                    .addAnalyzer(ApproxCountDistinct('payment_type')) \\\n",
    "                    .addAnalyzer(Mean('passenger_count')) \\\n",
    "                    .addAnalyzer(Correlation('payment_type', 'tip_amount')) \\\n",
    "                    .addAnalyzer(Compliance('more-5 passenger_count', 'passenger_count >= 5')) \\\n",
    "                    .addAnalyzer(Compliance('less-0 passenger_count', 'passenger_count <= 0')) \\\n",
    "                    .run()\n",
    "                    \n",
    "analysisResult_df = AnalyzerContext.successMetricsAsDataFrame(spark, analysisResult)\n",
    "analysisResult_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2563b7a9-4d0d-4ef7-a05e-c4be0bc1cded",
   "metadata": {},
   "source": [
    "## Silver zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e67e1683-51d4-4a25-aeff-341905df6498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|namespace     |\n",
      "+--------------+\n",
      "|adventureworks|\n",
      "|default       |\n",
      "|otherdb       |\n",
      "|warehouse     |\n",
      "+--------------+\n",
      "\n",
      "+----------------+\n",
      "|current_database|\n",
      "+----------------+\n",
      "|otherdb         |\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('CREATE DATABASE IF NOT EXISTS Warehouse')\n",
    "spark.sql('SHOW DATABASES').show(truncate=False)\n",
    "spark.sql('SELECT current_schema() AS current_database').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e191fe1e-31ac-4480-a93a-ecee4ef039f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "SELECT\n",
    "    p.ProductID,\n",
    "    p.Name AS ProductName,\n",
    "    p.Color,\n",
    "    p.Size,\n",
    "    p.Weight,\n",
    "    sc.Name AS SubCategory,\n",
    "    c.Name AS Category\n",
    "FROM AdventureWorks.Product p\n",
    "LEFT JOIN AdventureWorks.ProductSubCategory sc ON p.ProductSubcategoryID = sc.ProductSubcategoryID\n",
    "LEFT JOIN AdventureWorks.ProductCategory c ON sc.ProductCategoryID = c.ProductCategoryID\n",
    "'''\n",
    "\n",
    "data = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3212de86-1f88-4415-af16-5fe9f34ae4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|database_name|table_name|\n",
      "+-------------+----------+\n",
      "|warehouse    |dimproduct|\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS Warehouse.DimProduct (\n",
    "    Sk INT NOT NULL,\n",
    "    ProductID INT,\n",
    "    ProductName STRING,\n",
    "    Color STRING,\n",
    "    Size STRING,\n",
    "    Weight DECIMAL(8,2),\n",
    "    SubCategory STRING,\n",
    "    Category STRING,\n",
    "    StartDate TIMESTAMP,\n",
    "    EndDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/silver/Warehouse/DimProduct'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN Warehouse')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b3b16b60-a5a7-4708-8579-9a87f6f5e61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Sk</th><th>ProductID</th><th>ProductName</th><th>Color</th><th>Size</th><th>Weight</th><th>SubCategory</th><th>Category</th><th>StartDate</th><th>EndDate</th></tr>\n",
       "<tr><td>1</td><td>1</td><td>Adjustable Race</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "<tr><td>2</td><td>2</td><td>Bearing Ball</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "<tr><td>3</td><td>3</td><td>BB Ball Bearing</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>NULL</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+---------+---------------+-----+----+------+-----------+--------+--------------------+-------+\n",
       "| Sk|ProductID|    ProductName|Color|Size|Weight|SubCategory|Category|           StartDate|EndDate|\n",
       "+---+---------+---------------+-----+----+------+-----------+--------+--------------------+-------+\n",
       "|  1|        1|Adjustable Race| NULL|NULL|  NULL|       NULL|    NULL|2024-11-01 10:37:...|   NULL|\n",
       "|  2|        2|   Bearing Ball| NULL|NULL|  NULL|       NULL|    NULL|2024-11-01 10:37:...|   NULL|\n",
       "|  3|        3|BB Ball Bearing| NULL|NULL|  NULL|       NULL|    NULL|2024-11-01 10:37:...|   NULL|\n",
       "+---+---------+---------------+-----+----+------+-----------+--------+--------------------+-------+"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create Dimension with SCD type 2 support\n",
    "\n",
    "sql = '''\n",
    "INSERT INTO Warehouse.DimProduct\n",
    "SELECT\n",
    "    ROW_NUMBER() OVER(ORDER BY NULL) + (SELECT COALESCE(MAX(Sk), 0) FROM Warehouse.DimProduct) AS Sk,\n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS StartDate, \n",
    "    NULL as EndDate\n",
    "FROM {df}\n",
    "'''\n",
    "\n",
    "spark.sql(sql, df = data)\n",
    "spark.sql('SELECT * FROM Warehouse.DimProduct LIMIT 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "600eb0d6-e6b3-4fef-bce0-cc2cc1062eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create fact order\n",
    "\n",
    "sql = '''\n",
    "SELECT\n",
    "    soh.SalesOrderID AS OrderId,\n",
    "    sod.SalesOrderDetailID AS OrderDetailsId,\n",
    "    CAST(soh.OrderDate AS DATE) AS OrderDate,\n",
    "    soh.CustomerID AS CustomerId,\n",
    "    sod.ProductID AS ProductId,\n",
    "    sod.OrderQty AS Quantity,\n",
    "    sod.UnitPrice AS Price\n",
    "FROM AdventureWorks.SalesOrderHeader soh\n",
    "LEFT JOIN AdventureWorks.SalesOrderDetail sod ON soh.SalesOrderID = sod.SalesOrderID\n",
    "'''\n",
    "\n",
    "data = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe5ba954-640a-40f2-95c9-4ee2d07c5d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|database_name|table_name|\n",
      "+-------------+----------+\n",
      "|warehouse    |dimproduct|\n",
      "|warehouse    |factorder |\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS Warehouse.FactOrder (\n",
    "    OrderId INT,\n",
    "    OrderDetailsId INT,\n",
    "    OrderDate DATE,\n",
    "    CustomerId INT,\n",
    "    ProductId INT,\n",
    "    Quantity SMALLINT,\n",
    "    Price DECIMAL(19,4)\n",
    ") USING DELTA LOCATION '../lake/silver/Warehouse/FactOrder'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN Warehouse')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f9377d7b-a6b4-4e80-9614-50ee8bb00bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>OrderId</th><th>OrderDetailsId</th><th>OrderDate</th><th>CustomerId</th><th>ProductId</th><th>Quantity</th><th>Price</th></tr>\n",
       "<tr><td>43659</td><td>12</td><td>2011-05-31</td><td>29825</td><td>711</td><td>4</td><td>20.1865</td></tr>\n",
       "<tr><td>43659</td><td>11</td><td>2011-05-31</td><td>29825</td><td>712</td><td>2</td><td>5.1865</td></tr>\n",
       "<tr><td>43659</td><td>10</td><td>2011-05-31</td><td>29825</td><td>709</td><td>6</td><td>5.7000</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+--------------+----------+----------+---------+--------+-------+\n",
       "|OrderId|OrderDetailsId| OrderDate|CustomerId|ProductId|Quantity|  Price|\n",
       "+-------+--------------+----------+----------+---------+--------+-------+\n",
       "|  43659|            12|2011-05-31|     29825|      711|       4|20.1865|\n",
       "|  43659|            11|2011-05-31|     29825|      712|       2| 5.1865|\n",
       "|  43659|            10|2011-05-31|     29825|      709|       6| 5.7000|\n",
       "+-------+--------------+----------+----------+---------+--------+-------+"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO Warehouse.FactOrder\n",
    "    SELECT * FROM {df}\n",
    "''', df = data)\n",
    "\n",
    "spark.sql('SELECT * FROM Warehouse.FactOrder LIMIT 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "403fb4fe-992c-47ad-ba82-90c0b00468d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|min(OrderDate)|max(OrderDate)|\n",
      "+--------------+--------------+\n",
      "|2011-05-31    |2014-06-30    |\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create dimension date\n",
    "\n",
    "spark.sql('SELECT MIN(OrderDate), MAX(OrderDate) FROM Warehouse.FactOrder').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "061defd8-3008-4c78-a152-ff5c9e61213d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "sql = '''\n",
    "SELECT \n",
    "    date_key AS DateKey,\n",
    "    YEAR(date_key) AS Year,\n",
    "    MONTH(date_key) AS MonthKey,\n",
    "    MONTHNAME(date_key) AS MonthName,\n",
    "    DAY(date_key) AS Day,\n",
    "    DAYNAME(date_key) AS DayName,\n",
    "    DAYOFYEAR(date_key) AS DayOfYear,\n",
    "    DAYOFMONTH(date_key) AS DayOfMonth,\n",
    "    QUARTER(date_key) AS Quarter\n",
    "FROM (\n",
    "        SELECT CAST(range AS DATE) AS date_key FROM RANGE(DATE '2011-05-30', DATE '2014-06-29', INTERVAL 1 DAY)\n",
    ") q\n",
    "'''\n",
    "\n",
    "data = spark.createDataFrame( \n",
    "    duckdb.sql(sql).df()\n",
    ")\n",
    "\n",
    "data = data.withColumn('DateKey', col('DateKey').cast('date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55bafcec-18c4-4976-9844-1462195600a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+\n",
      "|database_name|table_name|\n",
      "+-------------+----------+\n",
      "|warehouse    |dimdate   |\n",
      "|warehouse    |dimproduct|\n",
      "|warehouse    |factorder |\n",
      "+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS Warehouse.DimDate (\n",
    "    Sk INT NOT NULL,\n",
    "    DateKey DATE,\n",
    "    Year BIGINT,\n",
    "    MonthKey BIGINT,\n",
    "    MonthName STRING,\n",
    "    Day BIGINT,\n",
    "    DayName STRING,\n",
    "    DayOfYear BIGINT,\n",
    "    DayOfMonth BIGINT,\n",
    "    Quarter BIGINT,\n",
    "    StartDate TIMESTAMP,\n",
    "    EndDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/silver/Warehouse/DimDate'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN Warehouse')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4344c60e-8686-49ed-b81e-df8f5dd344e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Sk</th><th>DateKey</th><th>Year</th><th>MonthKey</th><th>MonthName</th><th>Day</th><th>DayName</th><th>DayOfYear</th><th>DayOfMonth</th><th>Quarter</th><th>StartDate</th><th>EndDate</th></tr>\n",
       "<tr><td>1</td><td>2011-05-30</td><td>2011</td><td>5</td><td>May</td><td>30</td><td>Monday</td><td>150</td><td>30</td><td>2</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "<tr><td>2</td><td>2011-05-31</td><td>2011</td><td>5</td><td>May</td><td>31</td><td>Tuesday</td><td>151</td><td>31</td><td>2</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "<tr><td>3</td><td>2011-06-01</td><td>2011</td><td>6</td><td>June</td><td>1</td><td>Wednesday</td><td>152</td><td>1</td><td>2</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+----------+----+--------+---------+---+---------+---------+----------+-------+--------------------+-------+\n",
       "| Sk|   DateKey|Year|MonthKey|MonthName|Day|  DayName|DayOfYear|DayOfMonth|Quarter|           StartDate|EndDate|\n",
       "+---+----------+----+--------+---------+---+---------+---------+----------+-------+--------------------+-------+\n",
       "|  1|2011-05-30|2011|       5|      May| 30|   Monday|      150|        30|      2|2024-11-01 10:37:...|   NULL|\n",
       "|  2|2011-05-31|2011|       5|      May| 31|  Tuesday|      151|        31|      2|2024-11-01 10:37:...|   NULL|\n",
       "|  3|2011-06-01|2011|       6|     June|  1|Wednesday|      152|         1|      2|2024-11-01 10:37:...|   NULL|\n",
       "+---+----------+----+--------+---------+---+---------+---------+----------+-------+--------------------+-------+"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "INSERT INTO Warehouse.DimDate\n",
    "SELECT\n",
    "    ROW_NUMBER() OVER(ORDER BY NULL) + (SELECT COALESCE(MAX(Sk), 0) FROM Warehouse.DimDate) AS Sk,\n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS StartDate, \n",
    "    NULL as EndDate\n",
    "FROM {df}\n",
    "'''\n",
    "\n",
    "spark.sql(sql, df = data)\n",
    "spark.sql('SELECT * FROM Warehouse.DimDate LIMIT 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a9da2e0-5e5e-411f-856f-08ae16087ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dimension customer\n",
    "\n",
    "sql = '''\n",
    "SELECT\n",
    "\tc.CustomerID,\n",
    "\tCONCAT(\n",
    "\t\tCOALESCE(p.FirstName, ''), ' ',\n",
    "\t\tCOALESCE(p.MiddleName, ''), ' ',\n",
    "\t\tCOALESCE (p.LastName, '')\n",
    "\t) AS FullName,\n",
    "\tea.EmailAddress,\n",
    "\tpp.PhoneNumber \n",
    "FROM AdventureWorks.Customer c\n",
    "INNER JOIN AdventureWorks.Person p ON c.PersonID = p.BusinessEntityID\n",
    "INNER JOIN AdventureWorks.BusinessEntity be ON be.BusinessEntityID = p.BusinessEntityID \n",
    "INNER JOIN AdventureWorks.EmailAddress ea ON ea.BusinessEntityID = be.BusinessEntityID \n",
    "INNER JOIN AdventureWorks.PersonPhone pp ON pp.BusinessEntityID = be.BusinessEntityID \n",
    "'''\n",
    "\n",
    "data = spark.sql(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f18e986c-bd9a-4d1e-b265-e7c961703a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|database_name|table_name |\n",
      "+-------------+-----------+\n",
      "|warehouse    |dimcustomer|\n",
      "|warehouse    |dimdate    |\n",
      "|warehouse    |dimproduct |\n",
      "|warehouse    |factorder  |\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS Warehouse.DimCustomer (\n",
    "    Sk INT NOT NULL,\n",
    "    CustomerID INT,\n",
    "    FullName STRING,\n",
    "    EmailAddress STRING,\n",
    "    PhoneNumber STRING,\n",
    "    StartDate TIMESTAMP,\n",
    "    EndDate TIMESTAMP\n",
    ") USING DELTA LOCATION '../lake/silver/Warehouse/DimCustomer'\n",
    "'''\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN Warehouse')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4e664d7-c4e2-4389-8270-77ff43ed5398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Sk</th><th>CustomerID</th><th>FullName</th><th>EmailAddress</th><th>PhoneNumber</th><th>StartDate</th><th>EndDate</th></tr>\n",
       "<tr><td>1</td><td>29484</td><td>Gustavo  Achong</td><td>gustavo0@adventur...</td><td>398-555-0132</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "<tr><td>2</td><td>29485</td><td>Catherine R. Abel</td><td>catherine0@advent...</td><td>747-555-0171</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "<tr><td>3</td><td>29486</td><td>Kim  Abercrombie</td><td>kim2@adventure-wo...</td><td>334-555-0137</td><td>2024-11-01 10:37:...</td><td>NULL</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+---+----------+-----------------+--------------------+------------+--------------------+-------+\n",
       "| Sk|CustomerID|         FullName|        EmailAddress| PhoneNumber|           StartDate|EndDate|\n",
       "+---+----------+-----------------+--------------------+------------+--------------------+-------+\n",
       "|  1|     29484|  Gustavo  Achong|gustavo0@adventur...|398-555-0132|2024-11-01 10:37:...|   NULL|\n",
       "|  2|     29485|Catherine R. Abel|catherine0@advent...|747-555-0171|2024-11-01 10:37:...|   NULL|\n",
       "|  3|     29486| Kim  Abercrombie|kim2@adventure-wo...|334-555-0137|2024-11-01 10:37:...|   NULL|\n",
       "+---+----------+-----------------+--------------------+------------+--------------------+-------+"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = '''\n",
    "INSERT INTO Warehouse.DimCustomer\n",
    "SELECT\n",
    "    ROW_NUMBER() OVER(ORDER BY NULL) + (SELECT COALESCE(MAX(Sk), 0) FROM Warehouse.DimCustomer) AS Sk,\n",
    "    *,\n",
    "    CURRENT_TIMESTAMP() AS StartDate, \n",
    "    NULL AS EndDate\n",
    "FROM {df}\n",
    "'''\n",
    "\n",
    "spark.sql(sql, df = data)\n",
    "spark.sql('SELECT * FROM Warehouse.DimCustomer LIMIT 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81d767a-6751-409a-b20d-1aac5b41056e",
   "metadata": {},
   "source": [
    "## Farsi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45467331-09b0-4985-ae64-04c4764698fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------+\n",
      "|column_name          |data_type|\n",
      "+---------------------+---------+\n",
      "|ID_Order             |int      |\n",
      "|ID_Customer          |int      |\n",
      "|ID_Item              |int      |\n",
      "|DateTime_CartFinalize|timestamp|\n",
      "|Amount_Gross_Order   |double   |\n",
      "|city_name_fa         |string   |\n",
      "|Quantity_item        |double   |\n",
      "+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "digikala_df = spark.read.option('header', 'true').option('inferSchema', 'true').option('delimiter', ',').csv('../../data/digikala/digikala_orders.csv')\n",
    "spark.createDataFrame(digikala_df.dtypes, ['column_name', 'data_type']).show(digikala_df.count(), truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7a0e51a9-d5b9-4634-928c-a9ad60252748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>ID_Order</th><th>ID_Customer</th><th>ID_Item</th><th>DateTime_CartFinalize</th><th>Amount_Gross_Order</th><th>city_name_fa</th><th>Quantity_item</th></tr>\n",
       "<tr><td>2714054</td><td>469662</td><td>21386</td><td>2015-10-15 08:50:56</td><td>597982.0</td><td>محمود آباد</td><td>1.0</td></tr>\n",
       "<tr><td>11104039</td><td>3063877</td><td>248497</td><td>2018-02-11 00:29:26</td><td>980000.0</td><td>خرمدره</td><td>1.0</td></tr>\n",
       "<tr><td>4228130</td><td>3184893</td><td>50144</td><td>2016-06-14 00:30:08</td><td>229358.0</td><td>قرچک</td><td>1.0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------+-----------+-------+---------------------+------------------+------------+-------------+\n",
       "|ID_Order|ID_Customer|ID_Item|DateTime_CartFinalize|Amount_Gross_Order|city_name_fa|Quantity_item|\n",
       "+--------+-----------+-------+---------------------+------------------+------------+-------------+\n",
       "| 2714054|     469662|  21386|  2015-10-15 08:50:56|          597982.0|  محمود آباد|          1.0|\n",
       "|11104039|    3063877| 248497|  2018-02-11 00:29:26|          980000.0|      خرمدره|          1.0|\n",
       "| 4228130|    3184893|  50144|  2016-06-14 00:30:08|          229358.0|        قرچک|          1.0|\n",
       "+--------+-----------+-------+---------------------+------------------+------------+-------------+"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    SELECT * FROM {df} LIMIT 3\n",
    "''', df = digikala_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9fcc0798-96b7-4045-b4f7-a8e2b48489fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|database_name|table_name      |\n",
      "+-------------+----------------+\n",
      "|otherdb      |crime           |\n",
      "|otherdb      |dg_orders       |\n",
      "|otherdb      |trip            |\n",
      "|otherdb      |vw_crime        |\n",
      "|otherdb      |vw_trip_duration|\n",
      "|otherdb      |vw_trip_report  |\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql = '''\n",
    "CREATE TABLE IF NOT EXISTS OtherDB.dg_Orders (\n",
    "    OrderID INT,\n",
    "    CustomerID INT,\n",
    "    ProductID INT,\n",
    "    OrderDate TIMESTAMP,\n",
    "    Amount DOUBLE,\n",
    "    Quantity DOUBLE,\n",
    "    CityName STRING\n",
    ") USING DELTA LOCATION '../lake/bronze/OtherDB/dg_orders'\n",
    "'''\n",
    "\n",
    "\n",
    "spark.sql(sql)\n",
    "spark.sql('SELECT namespace as database_name, tableName as table_name FROM {df}', df = spark.sql('SHOW TABLES IN OtherDB')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2587f90e-e5cc-4d34-9445-806133394516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>OrderID</th><th>CustomerID</th><th>ProductID</th><th>OrderDate</th><th>Amount</th><th>Quantity</th><th>CityName</th></tr>\n",
       "<tr><td>1496884</td><td>468717</td><td>20187</td><td>2014-11-05 16:05:03</td><td>2844074.0</td><td>1.0</td><td>کرج</td></tr>\n",
       "<tr><td>5958461</td><td>2397262</td><td>78180</td><td>2017-01-02 22:03:04</td><td>369450.0</td><td>1.0</td><td>کرمانشاه</td></tr>\n",
       "<tr><td>6345216</td><td>1040870</td><td>273295</td><td>2017-02-11 01:20:22</td><td>156789.0</td><td>1.0</td><td>قزوین</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------+----------+---------+-------------------+---------+--------+--------+\n",
       "|OrderID|CustomerID|ProductID|          OrderDate|   Amount|Quantity|CityName|\n",
       "+-------+----------+---------+-------------------+---------+--------+--------+\n",
       "|1496884|    468717|    20187|2014-11-05 16:05:03|2844074.0|     1.0|     کرج|\n",
       "|5958461|   2397262|    78180|2017-01-02 22:03:04| 369450.0|     1.0|کرمانشاه|\n",
       "|6345216|   1040870|   273295|2017-02-11 01:20:22| 156789.0|     1.0|   قزوین|\n",
       "+-------+----------+---------+-------------------+---------+--------+--------+"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    INSERT INTO OtherDB.dg_Orders\n",
    "    SELECT ID_Order, ID_Customer, ID_Item, DateTime_CartFinalize, Amount_Gross_Order, Quantity_item, city_name_fa\n",
    "    FROM {df}\n",
    "''', df = digikala_df)\n",
    "\n",
    "spark.sql('SELECT * FROM OtherDB.dg_Orders LIMIT 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea2c8b93-6248-4666-9d49-78e931d86c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad4151-c803-40c6-a996-b788d50f0ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
